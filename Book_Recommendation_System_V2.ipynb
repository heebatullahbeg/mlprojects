{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFsRJj84Ist3HLxNcY0GrI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hebabeg/mlprojects/blob/main/Book_Recommendation_System_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Q5s8mMYUTIZU",
        "outputId": "490956cf-a01e-4135-9dcc-12bbb583eb3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.13.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.6.0 (from gradio)\n",
            "  Downloading gradio_client-1.6.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.5)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.13.1-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.6.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.7 ffmpy-0.5.0 gradio-5.13.1 gradio-client-1.6.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.3 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def generate_book_visualizations(books):\n",
        "    \"\"\"\n",
        "    Generate comprehensive visualizations for book dataset\n",
        "\n",
        "    Args:\n",
        "        books (pd.DataFrame): Processed book dataset\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert 'Num_Ratings' to numeric, handling commas\n",
        "    books['Num_Ratings'] = books['Num_Ratings'].str.replace(',', '', regex=True).astype(float)\n",
        "\n",
        "    plt.figure(figsize=(20, 15))\n",
        "\n",
        "    # 1. Correlation Matrix\n",
        "    plt.subplot(2, 2, 1)\n",
        "    numeric_columns = ['Avg_Rating', 'Num_Ratings']\n",
        "    correlation_matrix = books[numeric_columns].corr()\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "    plt.title('Rating and Number of Ratings Correlation')\n",
        "\n",
        "\n",
        "    # 2. Genre Distribution\n",
        "    plt.subplot(2, 2, 2)\n",
        "    genre_counts = books['Genres'].str.split(',', expand=True).stack().value_counts().head(10)\n",
        "    genre_counts.plot(kind='bar')\n",
        "    plt.title('Top 10 Book Genres')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    # 3. Rating Distribution\n",
        "    plt.subplot(2, 2, 3)\n",
        "    books['Avg_Rating'].hist(bins=20)\n",
        "    plt.title('Book Rating Distribution')\n",
        "    plt.xlabel('Average Rating')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    # 4. Author Frequency\n",
        "    plt.subplot(2, 2, 4)\n",
        "    author_counts = books['Author'].value_counts().head(10)\n",
        "    author_counts.plot(kind='bar')\n",
        "    plt.title('Top 10 Authors by Book Count')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('book_recommendation_visualizations.png')\n",
        "    plt.close()\n",
        "\n",
        "def analyze_book_data(books):\n",
        "    \"\"\"\n",
        "    Provide detailed analysis of book dataset\n",
        "\n",
        "    Args:\n",
        "        books (pd.DataFrame): Processed book dataset\n",
        "\n",
        "    Returns:\n",
        "        dict: Dataset insights\n",
        "    \"\"\"\n",
        "    insights = {\n",
        "        'total_books': len(books),\n",
        "        'unique_authors': books['Author'].nunique(),\n",
        "        'unique_genres': len(set(genre for genres in books['Genres'].str.split(',') for genre in genres)),\n",
        "        'avg_rating_stats': {\n",
        "            'mean': books['Avg_Rating'].mean(),\n",
        "            'median': books['Avg_Rating'].median(),\n",
        "            'std': books['Avg_Rating'].std()\n",
        "        },\n",
        "        'rating_distribution': books['Avg_Rating'].value_counts(bins=5).to_dict()\n",
        "    }\n",
        "\n",
        "    return insights\n",
        "\n",
        "\n",
        "generate_book_visualizations(books)\n",
        "dataset_insights = analyze_book_data(books)\n",
        "print(dataset_insights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezW1YnxSYI20",
        "outputId": "0cce39fe-3e03-492e-e29e-aa1c1682efd0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_books': 10000, 'unique_authors': 6064, 'unique_genres': 1315, 'avg_rating_stats': {'mean': 4.068576999999999, 'median': 4.08, 'std': 0.3353586015150974}, 'rating_distribution': {Interval(4.0, 5.0, closed='right'): 5910, Interval(3.0, 4.0, closed='right'): 4057, Interval(2.0, 3.0, closed='right'): 22, Interval(-0.006, 1.0, closed='right'): 9, Interval(1.0, 2.0, closed='right'): 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import difflib\n",
        "\n",
        "class BookRecommendationSystem:\n",
        "    def __init__(self, books_df):\n",
        "        self.books = books_df\n",
        "        self.prepare_recommendation_system()\n",
        "\n",
        "    def prepare_recommendation_system(self):\n",
        "\n",
        "        self.books['Description'] = self.books['Description'].fillna('')\n",
        "        self.books['Genres'] = self.books['Genres'].fillna('')\n",
        "        self.books['Author'] = self.books['Author'].fillna('')\n",
        "\n",
        "        books_data_features = (\n",
        "            self.books['Description'] + ' ' +\n",
        "            self.books['Genres'] + ' ' +\n",
        "            self.books['Author']\n",
        "        )\n",
        "\n",
        "\n",
        "        self.vector = TfidfVectorizer()\n",
        "        feature_vector = self.vector.fit_transform(books_data_features)\n",
        "\n",
        "\n",
        "        self.similarity = cosine_similarity(feature_vector)\n",
        "\n",
        "    def get_recommendations(self, book_title, num_recommendations=10):\n",
        "        titles_list = self.books['Book'].tolist()\n",
        "\n",
        "\n",
        "        book_match = difflib.get_close_matches(book_title, titles_list)[0]\n",
        "        book_index = self.books[self.books.Book == book_match].index[0]\n",
        "\n",
        "\n",
        "        similarity_score = list(enumerate(self.similarity[book_index]))\n",
        "        similar_books = sorted(similarity_score, key=lambda x: x[1], reverse=True)[1:num_recommendations+1]\n",
        "\n",
        "        recommended_books = []\n",
        "        for book in similar_books:\n",
        "            index = book[0]\n",
        "            recommended_books.append({\n",
        "                'title': self.books.loc[index, 'Book'],\n",
        "                'author': self.books.loc[index, 'Author'],\n",
        "                'genres': self.books.loc[index, 'Genres'],\n",
        "                'rating': self.books.loc[index, 'Avg_Rating'],\n",
        "                'similarity_score': book[1]\n",
        "            })\n",
        "\n",
        "        return recommended_books\n",
        "\n",
        "def create_recommendation_interface(book_recommendation_system):\n",
        "    def recommend_books(book_title):\n",
        "        try:\n",
        "            recommendations = book_recommendation_system.get_recommendations(book_title)\n",
        "            recommendation_text = \"\\n\".join([\n",
        "                f\"Title: {rec['title']}\\n\"\n",
        "                f\"Author: {rec['author']}\\n\"\n",
        "                f\"Genres: {rec['genres']}\\n\"\n",
        "                f\"Rating: {rec['rating']:.2f}\\n\"\n",
        "                f\"Similarity Score: {rec['similarity_score']:.2f}\\n\"\n",
        "                \"---\" for rec in recommendations\n",
        "            ])\n",
        "            return recommendation_text\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "    iface = gr.Interface(\n",
        "        fn=recommend_books,\n",
        "        inputs=gr.Textbox(label=\"Enter a Book Title\"),\n",
        "        outputs=gr.Textbox(label=\"Recommended Books\"),\n",
        "        title=\"ğŸ“š Book Recommendation System\",\n",
        "        description=\"Find similar books based on content similarity!\"\n",
        "    )\n",
        "\n",
        "    return iface\n",
        "\n",
        "path = kagglehub.dataset_download(\"ishikajohari/best-books-10k-multi-genre-data\")\n",
        "\n",
        "\n",
        "\n",
        "books = pd.read_csv(path + \"/goodreads_data.csv\")\n",
        "recommendation_system = BookRecommendationSystem(books)\n",
        "interface = create_recommendation_interface(recommendation_system)\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "MeOgj46iZjQk",
        "outputId": "09bcd6b0-c581-41ac-a939-bc759f03a8e1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8022129c454dcd376d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8022129c454dcd376d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tz_mruF2aB2B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}